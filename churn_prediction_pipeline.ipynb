# ================================
# COMPLETE PREPROCESSING PIPELINE
# ================================

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import (
    OneHotEncoder,
    OrdinalEncoder,
    LabelEncoder,
    StandardScaler,
    MinMaxScaler
)
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report


# ================================
# 1. LOAD DATA
# ================================

df = pd.read_csv("/content/sample_data/customer_churn.csv")

df.columns = df.columns.str.strip()


# ================================
# 2. FEATURE ENGINEERING (5+)
# ================================

df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

# 1. Average Monthly Spend
df["AvgMonthlySpend"] = df["TotalCharges"] / (df["Tenure"] + 1)

# 2. Charges Difference
df["ChargesDifference"] = df["TotalCharges"] - (df["MonthlyCharges"] * df["Tenure"])

# 3. Long Term Customer Flag
df["IsLongTermCustomer"] = np.where(df["Tenure"] > 24, 1, 0)

# 4. High Monthly Charges Flag
df["HighMonthlyCharges"] = np.where(
    df["MonthlyCharges"] > df["MonthlyCharges"].median(), 1, 0
)

# 5. Senior Citizen Interaction Feature
df["SeniorCitizenTenureInteraction"] = df["SeniorCitizen"] * df["Tenure"]


# ================================
# 3. OUTLIER DETECTION (IQR)
# ================================

Q1 = df["MonthlyCharges"].quantile(0.25)
Q3 = df["MonthlyCharges"].quantile(0.75)
IQR = Q3 - Q1

lower = Q1 - 1.5 * IQR
upper = Q3 + 1.5 * IQR

df = df[(df["MonthlyCharges"] >= lower) &
        (df["MonthlyCharges"] <= upper)]


# ================================
# 4. ENCODING METHODS (3 TYPES)
# ================================

# Label Encoding (Target)
label_encoder = LabelEncoder()
df["Churn"] = label_encoder.fit_transform(df["Churn"])

# Ordinal Encoding
ordinal_cols = ["Contract"]
ordinal_categories = [["Month-to-month", "One year", "Two year"]]

# One Hot Encoding
categorical_cols = df.select_dtypes(include="object").columns.tolist()
onehot_cols = [
    col for col in categorical_cols
    if col not in ordinal_cols and col != "CustomerID"
]


# ================================
# 5. SCALING TECHNIQUES (2 TYPES)
# ================================

numerical_cols = df.select_dtypes(exclude="object").columns.tolist()
numerical_cols.remove("Churn")

minmax_cols = ["Tenure", "TotalCharges"]
standard_cols = [col for col in numerical_cols if col not in minmax_cols]


# ================================
# 6. PREPROCESSOR
# ================================

preprocessor = ColumnTransformer(
    transformers=[
        (
            "standard_scaling",
            Pipeline([
                ("imputer", SimpleImputer(strategy="median")),
                ("scaler", StandardScaler())
            ]),
            standard_cols
        ),
        (
            "minmax_scaling",
            Pipeline([
                ("imputer", SimpleImputer(strategy="median")),
                ("scaler", MinMaxScaler())
            ]),
            minmax_cols
        ),
        (
            "onehot_encoding",
            Pipeline([
                ("imputer", SimpleImputer(strategy="most_frequent")),
                ("encoder", OneHotEncoder(handle_unknown="ignore"))
            ]),
            onehot_cols
        ),
        (
            "ordinal_encoding",
            Pipeline([
                ("imputer", SimpleImputer(strategy="most_frequent")),
                ("encoder", OrdinalEncoder(categories=ordinal_categories))
            ]),
            ordinal_cols
        )
    ]
)


# ================================
# 7. TRAIN TEST SPLIT
# ================================

X = df.drop(["Churn", "CustomerID"], axis=1)
y = df["Churn"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


# ================================
# 8. FULL ML PIPELINE
# ================================

model_pipeline = Pipeline(steps=[
    ("preprocessing", preprocessor),
    ("model", LogisticRegression(max_iter=1000))
])


# ================================
# 9. TRAIN MODEL
# ================================

model_pipeline.fit(X_train, y_train)


# ================================
# 10. EVALUATION
# ================================

y_pred = model_pipeline.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))
